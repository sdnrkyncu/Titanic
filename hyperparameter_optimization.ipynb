{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91334696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10936965981495178\n"
     ]
    }
   ],
   "source": [
    "%run main.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75750e61",
   "metadata": {},
   "source": [
    "# Fine-Tune Your Model\n",
    "### (hyperparameter optimization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46432481",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073adbd0",
   "metadata": {},
   "source": [
    "All you need to do is tell it which hyperparameters you want it to experiment with <br> \n",
    "and what values to try out, <br>\n",
    "and it will use cross-validation to evaluate all the possible combinations of hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a03436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e6214",
   "metadata": {},
   "source": [
    "**Hyperparameter Optimization for Linear Regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34c95654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'copy_X': True,\n",
       " 'fit_intercept': True,\n",
       " 'n_jobs': None,\n",
       " 'normalize': 'deprecated',\n",
       " 'positive': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e549929b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_param_grid = [{\"fit_intercept\": [True, False], \"normalize\": [True, False]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae6589ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_grid_search = GridSearchCV(lin_reg, lin_reg_param_grid, cv=5, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06112332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LinearRegression(),\n",
       "             param_grid=[{'fit_intercept': [True, False],\n",
       "                          'normalize': [True, False]}],\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg_grid_search.fit(titanic_clean, titanic_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f83f6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'fit_intercept': True, 'normalize': True}\n",
      " Best estimator: LinearRegression(normalize=True)\n"
     ]
    }
   ],
   "source": [
    "# best combination of paramaters and best estimator directly\n",
    "print(f\"Best parameters: {lin_reg_grid_search.best_params_}\\n\",\n",
    "     f\"Best estimator: {lin_reg_grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f6cf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([0.00290632, 0.00245008, 0.00233073, 0.00191875]), 'std_fit_time': array([0.00180168, 0.00156326, 0.00089516, 0.00197744]), 'mean_score_time': array([0.00044355, 0.0015728 , 0.00078278, 0.00033011]), 'std_score_time': array([8.87796776e-05, 1.75411277e-03, 5.91135073e-04, 7.95943349e-05]), 'param_fit_intercept': masked_array(data=[True, True, False, False],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_normalize': masked_array(data=[True, False, True, False],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'fit_intercept': True, 'normalize': True}, {'fit_intercept': True, 'normalize': False}, {'fit_intercept': False, 'normalize': True}, {'fit_intercept': False, 'normalize': False}], 'split0_test_score': array([-0.15375341, -0.15375341, -0.15375341, -0.15375341]), 'split1_test_score': array([-0.1597815, -0.1597815, -0.1597815, -0.1597815]), 'split2_test_score': array([-0.16535456, -0.16535456, -0.16535456, -0.16535456]), 'split3_test_score': array([-0.18728075, -0.18728075, -0.18728075, -0.18728075]), 'split4_test_score': array([-0.14218568, -0.14218568, -0.14218568, -0.14218568]), 'mean_test_score': array([-0.16167118, -0.16167118, -0.16167118, -0.16167118]), 'std_test_score': array([0.01493562, 0.01493562, 0.01493562, 0.01493562]), 'rank_test_score': array([1, 1, 1, 1], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation scores are available\n",
    "cvres = lin_reg_grid_search.cv_results_\n",
    "print(cvres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f47ed93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.402083548341115 {'fit_intercept': True, 'normalize': True}\n",
      "0.402083548341115 {'fit_intercept': True, 'normalize': False}\n",
      "0.402083548341115 {'fit_intercept': False, 'normalize': True}\n",
      "0.402083548341115 {'fit_intercept': False, 'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5454a7",
   "metadata": {},
   "source": [
    "**Hyperparameter Optimization for RandomForestRegressor model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9487a2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe6f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg_param_grid = [\n",
    "{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "{'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84fbbd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg_grid_search = GridSearchCV(forest_reg, forest_reg_param_grid, cv=5, scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a1c6f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 90.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-0.19121393 -0.17085825 -0.16846324 -0.2060136  -0.16744896 -0.16320656\n",
      " -0.19926472 -0.17071084 -0.16558657         nan         nan         nan\n",
      " -0.20834057 -0.19757252 -0.21645843 -0.20273309 -0.20487774 -0.19627007]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg_grid_search.fit(titanic_clean, titanic_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad80e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_features': 4, 'n_estimators': 30}\n",
      " Best estimator: RandomForestRegressor(max_features=4, n_estimators=30, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {forest_reg_grid_search.best_params_}\\n\",\n",
    "     f\"Best estimator: {forest_reg_grid_search.best_estimator_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2ede93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys:dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_max_features', 'param_n_estimators', 'param_bootstrap', 'params', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score']) \n",
      "\n",
      "\n",
      " {'mean_fit_time': array([0.00725889, 0.01252971, 0.03106508, 0.00426607, 0.01196547,\n",
      "       0.0331358 , 0.00468397, 0.01270151, 0.03679752, 0.00195112,\n",
      "       0.00397468, 0.00869284, 0.00378733, 0.0106637 , 0.00421615,\n",
      "       0.01143889, 0.00529861, 0.01444397]), 'std_fit_time': array([0.0026178 , 0.00199494, 0.00048089, 0.000344  , 0.00038609,\n",
      "       0.00014892, 0.00031478, 0.00047716, 0.00045347, 0.00018457,\n",
      "       0.00074843, 0.00104809, 0.00052239, 0.0007575 , 0.00022539,\n",
      "       0.00096492, 0.00115634, 0.00106825]), 'mean_score_time': array([0.00144768, 0.00130076, 0.00252218, 0.00084343, 0.00130901,\n",
      "       0.00273643, 0.00085077, 0.00133805, 0.00266762, 0.        ,\n",
      "       0.        , 0.        , 0.00104094, 0.00150232, 0.0009706 ,\n",
      "       0.00161104, 0.00132236, 0.00133195]), 'std_score_time': array([6.12014483e-04, 1.18198920e-04, 5.21301882e-05, 1.03710777e-04,\n",
      "       7.71337129e-05, 2.36900772e-04, 1.43995553e-04, 2.25655869e-04,\n",
      "       2.88877317e-04, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
      "       3.38296423e-04, 2.40428719e-04, 2.53203629e-04, 3.90014332e-04,\n",
      "       6.44528187e-04, 1.02478795e-04]), 'param_max_features': masked_array(data=[2, 2, 2, 4, 4, 4, 6, 6, 6, 8, 8, 8, 2, 2, 3, 3, 4, 4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[3, 10, 30, 3, 10, 30, 3, 10, 30, 3, 10, 30, 3, 10, 3,\n",
      "                   10, 3, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_bootstrap': masked_array(data=[--, --, --, --, --, --, --, --, --, --, --, --, False,\n",
      "                   False, False, False, False, False],\n",
      "             mask=[ True,  True,  True,  True,  True,  True,  True,  True,\n",
      "                    True,  True,  True,  True, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_features': 2, 'n_estimators': 3}, {'max_features': 2, 'n_estimators': 10}, {'max_features': 2, 'n_estimators': 30}, {'max_features': 4, 'n_estimators': 3}, {'max_features': 4, 'n_estimators': 10}, {'max_features': 4, 'n_estimators': 30}, {'max_features': 6, 'n_estimators': 3}, {'max_features': 6, 'n_estimators': 10}, {'max_features': 6, 'n_estimators': 30}, {'max_features': 8, 'n_estimators': 3}, {'max_features': 8, 'n_estimators': 10}, {'max_features': 8, 'n_estimators': 30}, {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}, {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}, {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}, {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}, {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}, {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}], 'split0_test_score': array([-0.21521167, -0.18851865, -0.18388682, -0.24230537, -0.18657552,\n",
      "       -0.17845372, -0.22446616, -0.18623074, -0.17465498,         nan,\n",
      "               nan,         nan, -0.21883556, -0.21232873, -0.21821482,\n",
      "       -0.2069237 , -0.21604226, -0.20596514]), 'split1_test_score': array([-0.19791844, -0.17409023, -0.17079352, -0.19919805, -0.16294204,\n",
      "       -0.16209113, -0.21471689, -0.18093096, -0.1760938 ,         nan,\n",
      "               nan,         nan, -0.21012671, -0.19057077, -0.21718386,\n",
      "       -0.19692377, -0.20400589, -0.19321147]), 'split2_test_score': array([-0.16723734, -0.16114709, -0.15761056, -0.17913653, -0.15490703,\n",
      "       -0.15205273, -0.16590329, -0.14829994, -0.1495575 ,         nan,\n",
      "               nan,         nan, -0.21536881, -0.19343928, -0.22051862,\n",
      "       -0.1996057 , -0.18562782, -0.17553197]), 'split3_test_score': array([-0.20699463, -0.18336334, -0.18544213, -0.24255538, -0.19886389,\n",
      "       -0.19264503, -0.24389295, -0.20340584, -0.19093302,         nan,\n",
      "               nan,         nan, -0.22346395, -0.21995272, -0.23457468,\n",
      "       -0.23478817, -0.24331375, -0.22927162]), 'split4_test_score': array([-0.16870756, -0.14717194, -0.14458319, -0.16687266, -0.13395631,\n",
      "       -0.13079017, -0.14734429, -0.13468674, -0.13669355,         nan,\n",
      "               nan,         nan, -0.17390781, -0.17157113, -0.19180018,\n",
      "       -0.17542412, -0.175399  , -0.17737013]), 'mean_test_score': array([-0.19121393, -0.17085825, -0.16846324, -0.2060136 , -0.16744896,\n",
      "       -0.16320656, -0.19926472, -0.17071084, -0.16558657,         nan,\n",
      "               nan,         nan, -0.20834057, -0.19757252, -0.21645843,\n",
      "       -0.20273309, -0.20487774, -0.19627007]), 'std_test_score': array([0.01975493, 0.01506029, 0.01561818, 0.03147455, 0.02303082,\n",
      "       0.02133342, 0.03653567, 0.02535455, 0.01963068,        nan,\n",
      "              nan,        nan, 0.01775986, 0.01709269, 0.01382985,\n",
      "       0.0191541 , 0.02384235, 0.01989838]), 'rank_test_score': array([ 7,  6,  4, 13,  3,  1, 10,  5,  2, 16, 17, 18, 14,  9, 15, 11, 12,\n",
      "        8], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation scores are available\n",
    "forest_reg_cvres = forest_reg_grid_search.cv_results_\n",
    "print(f'keys:{forest_reg_cvres.keys()}', \"\\n\\n\\n\", forest_reg_cvres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05710bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43728015034129586 {'max_features': 2, 'n_estimators': 3}\n",
      "0.41335003278441307 {'max_features': 2, 'n_estimators': 10}\n",
      "0.4104427410040683 {'max_features': 2, 'n_estimators': 30}\n",
      "0.4538872098919531 {'max_features': 4, 'n_estimators': 3}\n",
      "0.4092052746971811 {'max_features': 4, 'n_estimators': 10}\n",
      "0.40398831168923277 {'max_features': 4, 'n_estimators': 30}\n",
      "0.4463907665247816 {'max_features': 6, 'n_estimators': 3}\n",
      "0.41317168743952215 {'max_features': 6, 'n_estimators': 10}\n",
      "0.4069232982305372 {'max_features': 6, 'n_estimators': 30}\n",
      "nan {'max_features': 8, 'n_estimators': 3}\n",
      "nan {'max_features': 8, 'n_estimators': 10}\n",
      "nan {'max_features': 8, 'n_estimators': 30}\n",
      "0.45644338856819855 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "0.44449130913950213 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "0.46525093527493144 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "0.4502589159002453 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "0.4526342284269093 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "0.44302377789198394 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "for mean_score, params in zip(forest_reg_cvres[\"mean_test_score\"], forest_reg_cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f11d495b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the importance of features\n",
    "best_estimator_grid = forest_reg_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d3c4db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = best_estimator_grid.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6ca8362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature: Age, importance: 0.29068027967507276\n",
      "feature: Fare, importance: 0.3957278163786874\n",
      "feature: Sex, importance: 0.27474567955709267\n",
      "feature: Embarked, importance: 0.013458922853767189\n"
     ]
    }
   ],
   "source": [
    "for feature, importance in zip((titanic_num + titanic_cat), feature_importances):\n",
    "    print(f'feature: {feature}, importance: {importance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe4be9b",
   "metadata": {},
   "source": [
    "## Randomized Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eee8b64",
   "metadata": {},
   "source": [
    "The grid search approach is fine when you are exploring relatively few combinations but RandomizedSearchCV is often preferable, especially when the hyperparameter search space is large. It is not the case for this project but let's learn it here anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1c28390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c45636",
   "metadata": {},
   "source": [
    "**Hyperparameter Optimization for RandomForestRegressor model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59b1f5fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36442060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': [False],\n",
       " 'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen at 0x7ff085c60d00>,\n",
       " 'max_features': <scipy.stats._distn_infrastructure.rv_frozen at 0x7ff085c687f0>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg_param_rand = {'n_estimators': randint(low=3, high=50), 'max_features': randint(low=2, high=16)},\n",
    "{'bootstrap': [False],'n_estimators': randint(low=3, high=50), 'max_features': randint(low=2, high=16)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0da9d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_reg_rand_search = RandomizedSearchCV(forest_reg, forest_reg_param_rand, cv=5, \n",
    "                                            scoring=\"neg_mean_squared_error\", random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b93b8303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/sudenur/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      " -0.16499069         nan -0.16199528 -0.18770236]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(random_state=42),\n",
       "                   param_distributions=({'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff085c60400>,\n",
       "                                         'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7ff085c60d90>},),\n",
       "                   random_state=42, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_reg_rand_search.fit(titanic_clean, titanic_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7028d907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_features': 4, 'n_estimators': 24}\n",
      " Best estimator: RandomForestRegressor(max_features=4, n_estimators=24, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best parameters: {forest_reg_rand_search.best_params_}\\n\",\n",
    "     f\"Best estimator: {forest_reg_rand_search.best_estimator_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
